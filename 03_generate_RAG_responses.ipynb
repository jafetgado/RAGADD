{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate RAG responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import evaluate\n",
    "import bert_score\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: sk-proj-Hw...\n"
     ]
    }
   ],
   "source": [
    "# Load OpenAI API from .env file\n",
    "load_dotenv(dotenv_path='./api.env') # Change this to your .env file\n",
    "print(f\"API key loaded: {os.getenv('OPENAI_API_KEY')[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_zeroshot_prediction(model_name='gpt-3.5-turbo', questions=[], temperature=0, top_p=1.0):\n",
    "\n",
    "    # Build a chain for zero-shot prediction with GPT-3.5-turbo\n",
    "    model = ChatOpenAI(model=model_name, temperature=0, top_p=top_p)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant that provides concise answers questions patients have about ADHD medication\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = \"\"\"\n",
    "    Answer the question provided below.\n",
    "    Your answer should be a few sentences and be concise.\n",
    "\n",
    "    Here is an example of how you should answer:\n",
    "\n",
    "    Question: What changes typically occur in a child’s mood or energy after starting Intuniv?\n",
    "    Answer: After starting Intuniv, children often experience increased calmness, reduced impulsivity, and better sleep. However, some also show decreased energy, fatigue, irritability, or emotional flatness. Responses vary depending on the dosage and individual sensitivity.\n",
    "\n",
    "    Use this style in your own answers.\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    #  Prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(user_prompt)\n",
    "    ])\n",
    "\n",
    "    # Chain\n",
    "    chain = (\n",
    "        {\"question\": lambda x: x}  # passthrough identity for each input question\n",
    "        | prompt\n",
    "        | model\n",
    "        | (lambda m: m.content)  # extract .content from AIMessage list\n",
    "    )\n",
    "    # Run the GPT-3.5-turbo pipeline over the questions\n",
    "    responses = chain.batch(questions)\n",
    "\n",
    "    # Text from responses\n",
    "    gentext = [item.split('Answer: ')[-1] for item in responses]\n",
    "    \n",
    "    return gentext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to run RAG with specified embeddings and vector stores\n",
    "\n",
    "def build_RAG_chain(model_name='gpt-3.5-turbo', temperature=0, top_p=1):\n",
    "    \"\"\"Return a LangChain pipeline for RAG generation\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant that provides concise, evidence-based answers to user questions based on patient-provided documents.\n",
    "    Your goal is to summarize real experiences with medical treatments as described in the text.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = \"\"\"\n",
    "    Based on the patient review document attached, answer the following question using only information found directly in the document. \n",
    "    Your answer should be a few sentences and be concise.\n",
    "    Avoid speculation, generalizations, or added interpretation. Focus only on what patients actually report.\n",
    "\n",
    "    Here is an example of how you should answer:\n",
    "\n",
    "    Question: What changes typically occur in a child’s mood or energy after starting Intuniv?\n",
    "    Answer: After starting Intuniv, children often experience increased calmness, reduced impulsivity, and better sleep. However, some also show decreased energy, fatigue, irritability, or emotional flatness. Responses vary depending on the dosage and individual sensitivity.\n",
    "\n",
    "    Use this style in your own answers.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    --- BEGIN DOCUMENT ---\n",
    "    {document_text}\n",
    "    --- END DOCUMENT ---\n",
    "    \"\"\"\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(user_prompt)\n",
    "    ])\n",
    "    \n",
    "    # Model and chain\n",
    "    model = ChatOpenAI(model=model_name, temperature=temperature, top_p=top_p)\n",
    "    chain = (\n",
    "        #lambda x: {'question': x[\"question\"], 'document_text': x['document_text']}\n",
    "        RunnableLambda(lambda x: {'question': x[\"question\"], 'document_text': x['document_text']})\n",
    "        | prompt\n",
    "        | model\n",
    "        | (lambda m: m.content)  # extract .content from AIMessage list\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_rag_chain(model_name, temperature, top_p, vectorstore, questions, rag_k=4):\n",
    "    \"\"\"Run a RAG chain over a list of questions using the specified model and vectorstore, returning the generated responses.\"\"\"\n",
    "\n",
    "    chain = build_RAG_chain(model_name=model_name, temperature=temperature, \n",
    "                            top_p=top_p)\n",
    "    responses = []\n",
    "    for question in questions:\n",
    "        document_text = vectorstore.similarity_search(query=question, k=rag_k)\n",
    "        document_text = \"\\n\".join([item.page_content for item in document_text])\n",
    "        response = chain.invoke({'question': question, 'document_text': document_text})\n",
    "        responses.append(response)\n",
    "\n",
    "    return responses\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_rag_model(model_name, vectorstore_path, embedding, questions, references, rag_k=5, \n",
    "                       temperature=0, top_p=1):\n",
    "    \"\"\"Runs the RAG pipeline with a specified model and embedding to generate answers and \n",
    "    compute performance metrics.\"\"\"\n",
    "\n",
    "    vectorstore = FAISS.load_local(\n",
    "        vectorstore_path, \n",
    "        embeddings=embedding, \n",
    "        allow_dangerous_deserialization=True\n",
    "        )\n",
    "    responses = run_rag_chain(\n",
    "        model_name=model_name, \n",
    "        vectorstore=vectorstore, \n",
    "        questions=questions, \n",
    "        temperature=temperature, \n",
    "        top_p=top_p,\n",
    "        rag_k=rag_k)\n",
    "    answers = [r.split('\\nAnswer: ')[-1] for r in responses]\n",
    "    results = compute_performance(references=references, candidates=answers)\n",
    "    \n",
    "    return answers, results\n",
    "\n",
    "\n",
    "def compute_performance(references, candidates):\n",
    "    \"\"\"Return a dictionary of Rouge and BERTScore metrics evaluating quality of a list \n",
    "    of generated candidates relative to a corresponding list of references\"\"\"\n",
    "    \n",
    "    rouge = evaluate.load('rouge')\n",
    "    results = rouge.compute(predictions=candidates, references=references)\n",
    "    bscores = bert_score.score(cands=candidates, refs=references, lang='en', \n",
    "                               model_type='bert-base-uncased', rescale_with_baseline=True)\n",
    "    bscores = np.asarray([item.numpy() for item in bscores]).mean(axis=-1) # Average over all samples\n",
    "    results.update(dict(zip(['bertscore_precision', 'bertscore_recall', 'bertscore_f1'], bscores)))\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "STORE = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data\n",
    "testdata = pd.read_csv('data/test_data.csv', index_col=None)\n",
    "questions = testdata['QUESTIONS'].tolist()\n",
    "answers = testdata['ANSWERS'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot with GPT-3.5\n",
    "responses = run_zeroshot_prediction(model_name='gpt-3.5-turbo', temperature=0.25, top_p=1, \n",
    "                                    questions=questions)\n",
    "\n",
    "# Save generated text\n",
    "with open(\"data/responses/test-data/gpt-3.5-test-zeroshot.txt\", 'w') as f:\n",
    "    for item in responses:\n",
    "        f.write(item + '\\n\\n')\n",
    "\n",
    "# Compute performance\n",
    "results = compute_performance(references=answers, candidates=responses)\n",
    "STORE['gpt-3.5-zeroshot'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot with GPT-4o\n",
    "responses = run_zeroshot_prediction(model_name='gpt-4o', temperature=0.25, top_p=1, \n",
    "                                    questions=questions)\n",
    "\n",
    "# Save generated text\n",
    "with open(\"data/responses/test-data/gpt-4o-test-zeroshot.txt\", 'w') as f:\n",
    "    for item in responses:\n",
    "        f.write(item + '\\n\\n')\n",
    "\n",
    "# Compute performance\n",
    "results = compute_performance(references=answers, candidates=responses)\n",
    "STORE['gpt-4o-zeroshot'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-RAG</th>\n",
       "      <td>0.358602</td>\n",
       "      <td>0.103362</td>\n",
       "      <td>0.226566</td>\n",
       "      <td>0.226559</td>\n",
       "      <td>0.520008</td>\n",
       "      <td>0.485802</td>\n",
       "      <td>0.502868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-zeroshot</th>\n",
       "      <td>0.325382</td>\n",
       "      <td>0.116079</td>\n",
       "      <td>0.223603</td>\n",
       "      <td>0.223681</td>\n",
       "      <td>0.493146</td>\n",
       "      <td>0.416614</td>\n",
       "      <td>0.453661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-zeroshot</th>\n",
       "      <td>0.361135</td>\n",
       "      <td>0.121577</td>\n",
       "      <td>0.242720</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>0.496800</td>\n",
       "      <td>0.478077</td>\n",
       "      <td>0.487848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rouge1    rouge2    rougeL  rougeLsum  \\\n",
       "gpt-3.5-RAG       0.358602  0.103362  0.226566   0.226559   \n",
       "gpt-3.5-zeroshot  0.325382  0.116079  0.223603   0.223681   \n",
       "gpt-4o-zeroshot   0.361135  0.121577  0.242720   0.243154   \n",
       "\n",
       "                  bertscore_precision  bertscore_recall  bertscore_f1  \n",
       "gpt-3.5-RAG                  0.520008          0.485802      0.502868  \n",
       "gpt-3.5-zeroshot             0.493146          0.416614      0.453661  \n",
       "gpt-4o-zeroshot              0.496800          0.478077      0.487848  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View zero-shot performance\n",
    "df = pd.DataFrame(STORE).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RAG on full test data with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RAG on full test data with optimal hyperparameters\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_name = 'text-embedding-3-large'\n",
    "embedding = OpenAIEmbeddings(model=embedding_name, show_progress_bar=False)            \n",
    "k = 15\n",
    "temperature = 0.25\n",
    "top_p = 1.0\n",
    "\n",
    "# Run rag\n",
    "responses, results = evaluate_rag_model(\n",
    "    model_name='gpt-3.5-turbo', # Generative model\n",
    "    vectorstore_path=f'data/vector-stores/{embedding_name}-dotP',\n",
    "    embedding=embedding,\n",
    "    questions=questions,\n",
    "    references=answers,\n",
    "    rag_k=k, \n",
    "    temperature=temperature, \n",
    "    top_p=top_p\n",
    "    )\n",
    "responses = [item.split('Answer: ')[-1] for item in responses]\n",
    "\n",
    "# Save responses\n",
    "with open(f\"data/responses/test-data/gpt-3.5-RAG.txt\", 'w') as f:\n",
    "    for item in responses:\n",
    "        f.write(item + '\\n\\n')    \n",
    "\n",
    "# Store results\n",
    "STORE[\"gpt-3.5-RAG\"] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-RAG</th>\n",
       "      <td>0.363274</td>\n",
       "      <td>0.105933</td>\n",
       "      <td>0.228388</td>\n",
       "      <td>0.228705</td>\n",
       "      <td>0.521517</td>\n",
       "      <td>0.490406</td>\n",
       "      <td>0.506286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-zeroshot</th>\n",
       "      <td>0.325382</td>\n",
       "      <td>0.116079</td>\n",
       "      <td>0.223603</td>\n",
       "      <td>0.223681</td>\n",
       "      <td>0.493146</td>\n",
       "      <td>0.416614</td>\n",
       "      <td>0.453661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-zeroshot</th>\n",
       "      <td>0.361135</td>\n",
       "      <td>0.121577</td>\n",
       "      <td>0.242720</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>0.496800</td>\n",
       "      <td>0.478077</td>\n",
       "      <td>0.487848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rouge1    rouge2    rougeL  rougeLsum  \\\n",
       "gpt-3.5-RAG       0.363274  0.105933  0.228388   0.228705   \n",
       "gpt-3.5-zeroshot  0.325382  0.116079  0.223603   0.223681   \n",
       "gpt-4o-zeroshot   0.361135  0.121577  0.242720   0.243154   \n",
       "\n",
       "                  bertscore_precision  bertscore_recall  bertscore_f1  \n",
       "gpt-3.5-RAG                  0.521517          0.490406      0.506286  \n",
       "gpt-3.5-zeroshot             0.493146          0.416614      0.453661  \n",
       "gpt-4o-zeroshot              0.496800          0.478077      0.487848  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View performance\n",
    "joblib.dump(STORE, 'data/test-results-store.pkl')\n",
    "df = pd.DataFrame(STORE).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results as bar graph\n",
    "dfsel = df.loc[:,'bertscore_f1'].sort_values()\n",
    "y = dfsel.values\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.barh(range(len(y)), y)\n",
    "plt.yticks(range(len(y)), dfsel.index);\n",
    "plt.xlabel('BERTScore (F1)');\n",
    "for i, val in enumerate(y):\n",
    "    plt.text(val + 0.002, i, f'{val:.3f}', va='center', fontsize=9)\n",
    "plt.xlim((0.35,0.535));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare an example response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do ADHD medications affect gut health?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "questions[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ADHD medications can sometimes cause gastrointestinal side effects such as stomach upset, nausea, or decreased appetite. However, there is limited evidence to suggest a direct impact on gut health. It's important to discuss any concerns with your healthcare provider.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT 3.5 zero-shot\n",
    "file = 'data/responses/test-data/gpt-3.5-test-zeroshot.txt'\n",
    "with open(file, 'r') as f:\n",
    "    text = f.read().strip().split('\\n\\n')\n",
    "text[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ADHD medications, particularly stimulants like methylphenidate and amphetamines, can affect gut health by causing side effects such as reduced appetite, stomach pain, nausea, or constipation. These effects are generally mild and temporary, but they can vary based on the individual and the specific medication. Non-stimulant medications may have different gastrointestinal side effects, and it's important to monitor any changes and discuss them with a healthcare provider.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT-4o zero-shot\n",
    "file = 'data/responses/test-data/gpt-4o-test-zeroshot.txt'\n",
    "with open(file, 'r') as f:\n",
    "    text = f.read().strip().split('\\n\\n')\n",
    "text[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some ADHD medications, such as Methylphenidate and Dexmethylphenidate, have been reported to cause side effects like diarrhea. Additionally, Strattera has been mentioned to cause constipation in some individuals. These gastrointestinal effects may vary among patients using these medications.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT-3.5 with RAG\n",
    "file = 'data/responses/test-data/gpt-3.5-RAG.txt'\n",
    "with open(file, 'r') as f:\n",
    "    text = f.read().strip().split('\\n\\n')\n",
    "text[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients report several gastrointestinal side effects from ADHD medications. Some individuals experienced nausea, diarrhea, constipation, and appetite loss. A few also mentioned weight loss associated with reduced food intake. One patient reported digestive discomfort linked to specific pill binders. Another noted that methylphenidate helped regulate their digestive tract. These effects vary by medication and individual.\n"
     ]
    }
   ],
   "source": [
    "# Ground truth (GPT-4o with all documents in context)\n",
    "print(answers[-2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
